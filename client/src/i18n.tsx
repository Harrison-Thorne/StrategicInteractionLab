import React, { createContext, useCallback, useContext, useMemo, useState } from 'react';

const en = {
  'lang.label': 'Language',
  'lang.en': 'EN',
  'lang.zh': '中文',
  'nav.brand': 'StrategicInteractionLab',
  'nav.arena': 'Arena',
  'nav.rl': 'RL Train',
  'nav.notes': 'Notes',
  'nav.eval': 'Eval',
  'nav.logout': 'Logout',
  'login.title': 'Login',
  'login.subtitle': 'Sign in to StrategicInteractionLab',
  'login.email': 'Email',
  'login.password': 'Password',
  'login.error': 'Login failed',
  'login.useTest': 'Use Test Account',
  'login.submit': 'Login',
  'login.session': 'Session-aware arena with repeated game simulations',
  'login.eval': 'Evaluation suite for online learning algorithms',
  'login.notes': 'Personal notes to capture experiment observations',
  'dashboard.artLabel': 'Multi-agent dynamics',
  'dashboard.artAlt': 'Interactive data visualization',
  'dashboard.greeting': 'Hi, {email}',
  'dashboard.live': 'Live Lab Session',
  'dashboard.gameTheory': 'Game-theoretic Experiments',
  'dashboard.metricEpisodes': 'Simulated Episodes (demo)',
  'dashboard.metricEpisodesChip': 'RPS / MP / PD',
  'dashboard.metricStrategies': 'Strategies Tracked',
  'dashboard.metricStrategiesChip': 'Hedge · Regret · FP',
  'dashboard.metricEval': 'Evaluation Runs',
  'dashboard.metricEvalChip': 'Exploration snapshot',
  'notes.title': 'Research Notebook',
  'notes.subtitle': 'Capture quick observations from arena runs or evaluation experiments.',
  'notes.pillTime': 'Time-stamped notes',
  'notes.pillUser': 'Per-user history',
  'notes.placeholder': 'Write a note...',
  'notes.add': 'Add',
  'notes.delete': 'Delete',
  'notes.empty': 'No notes yet.',
  'arena.title': 'Learning Dynamics Arena',
  'arena.subtitle': 'Run repeated games and visualize how online learning converges under different incentives.',
  'arena.pillRealtime': 'Real-time simulation',
  'arena.pillSocket': 'Socket.IO back-end',
  'arena.pillHeatmap': 'Heatmap + trajectory views',
  'arena.decisionTitle': 'Decision Trace',
  'arena.decisionSubtitle': 'See the exact actions taken by both players on every step.',
  'arena.downloadCsv': 'Download steps CSV',
  'arena.latestSteps': 'Latest steps',
  'arena.noSteps': 'No steps recorded yet.',
  'arena.avgRewardTitle': 'Average Reward (P1)',
  'arena.avgRewardSubtitle': 'Smoothed rewards over time with a moving window.',
  'arena.strategyTitle': 'Strategy Distribution (P1)',
  'arena.strategySubtitle': 'Track how the mixed strategy evolves under Hedge updates.',
  'arena.heatTitle': 'Joint Action Frequency',
  'arena.heatSubtitle': 'Empirical distribution over joint actions across the horizon.',
  'arena.control.game': 'Game',
  'arena.control.rps': 'Rock-Paper-Scissors',
  'arena.control.mp': 'Matching Pennies',
  'arena.control.pd': "Prisoner's Dilemma(2x2)",
  'arena.control.steps': 'Steps',
  'arena.control.seed': 'Seed',
  'arena.control.lr': 'Learning rate (Hedge)',
  'arena.control.backend': 'Backend mode',
  'arena.control.backendLabel': 'Use server (Socket.IO)',
  'arena.control.start': 'Start',
  'arena.control.stop': 'Stop',
  'arena.control.reset': 'Reset',
  'arena.control.time': 't = {t}',
  'arena.axis.t': 't',
  'arena.axis.reward': 'reward',
  'arena.axis.p1': 'P1',
  'arena.axis.p2': 'P2',
  'arena.axis.player': 'player',
  'arena.tooltip.freq': '{p1} vs {p2}<br/>freq: {freq}%',
  'arena.tooltip.decision': 't = {t}<br/>{player} played {action}<br/>reward: {reward}',
  'arena.label.p1': 'P1:',
  'arena.label.p2': 'P2:',
  'arena.label.r1': 'r1:',
  'arena.label.r2': 'r2:',
  'eval.title': 'Algorithm Evaluation Suite',
  'eval.subtitle': 'Batch experiments across seeds and episodes to compare learning algorithms quantitatively.',
  'eval.pillSummary': 'Summary statistics',
  'eval.pillDistribution': 'Distributional view',
  'eval.control.game': 'Game',
  'eval.control.algA': 'Alg A',
  'eval.control.algB': 'Alg B',
  'eval.alg.hedge': 'Hedge',
  'eval.alg.regret': 'Regret Matching',
  'eval.alg.fp': 'Fictitious Play',
  'eval.control.seeds': 'Seeds (comma)',
  'eval.control.episodes': 'Episodes',
  'eval.control.stepsPerEp': 'Steps/Ep',
  'eval.control.lr': 'lr',
  'eval.control.run': 'Run Eval',
  'eval.summary.winA': 'winA',
  'eval.summary.avgRewardA': 'avgRewardA',
  'eval.summary.coopRate': 'coopRate',
  'eval.summary.l2Dist': 'l2Dist',
  'eval.section.perStepTitle': 'Per-step Decisions',
  'eval.section.perStepSubtitle': 'Inspect every action taken during evaluation runs.',
  'eval.control.seed': 'Seed',
  'eval.control.episode': 'Episode',
  'eval.downloadTrace': 'Download steps CSV',
  'eval.noTrace': 'Run an evaluation to see step-level actions.',
  'eval.loadingTrace': 'Loading trace...',
  'eval.latestSteps': 'Latest steps (selected seed/episode)',
  'eval.noSteps': 'No steps recorded yet.',
  'eval.histTitle': 'A Win Rate Histogram',
  'eval.histSubtitle': "Distribution of A's win rate across independent seeds.",
  'eval.rewardTitle': 'Avg Reward by Episode',
  'eval.rewardSubtitle': 'Episode-level aggregation of average rewards for player A.',
  'eval.coopTitle': 'Cooperation Rate (A)',
  'eval.coopSubtitle': 'How often player A chooses cooperative actions in PD.',
  'eval.l2Title': 'L2 Distance to Uniform (A)',
  'eval.l2Subtitle': "How far A's strategy is from the uniform mixed strategy.",
  'eval.tooltip.decision': 'seed {seed} · ep {ep}<br/>t = {t}<br/>P{player} played {action}<br/>reward: {reward}',
  'eval.axis.t': 't',
  'eval.axis.player': 'player',
  'eval.axis.avgRewardA': 'avgRewardA',
  'eval.axis.coopRate': 'coopRate',
  'eval.axis.l2Dist': 'l2Dist',
  'eval.axis.count': 'count',
  'eval.label.a': 'A:',
  'eval.label.b': 'B:',
  'eval.label.rA': 'rA:',
  'eval.label.rB': 'rB:',
  'rl.title': 'Deep RL Trainer (Demo)',
  'rl.subtitle': 'CPU-only self-play policy-gradient trainer for small matrix games.',
  'rl.pillSelfPlay': 'Self-play PG',
  'rl.pillCpu': 'CPU friendly',
  'rl.pillDownload': 'Downloadable policy',
  'rl.control.game': 'Game',
  'rl.control.pd': "Prisoner's Dilemma",
  'rl.control.rps': 'RPS',
  'rl.control.mp': 'Matching Pennies',
  'rl.control.episodes': 'Episodes',
  'rl.control.stepsPerEp': 'Steps / Episode',
  'rl.control.lr': 'Learning rate',
  'rl.control.hidden': 'Hidden size',
  'rl.control.seed': 'Seed',
  'rl.control.distributed': 'Distributed demo',
  'rl.control.distributedLabel': 'Enable multi-worker aggregation',
  'rl.control.workers': 'Workers',
  'rl.control.train': 'Train',
  'rl.control.download': 'Download policy',
  'rl.chart.rewardTitle': 'Average Reward (A)',
  'rl.chart.rewardSubtitle': 'Reward trajectory across episodes.',
  'rl.chart.winTitle': 'Win Rate (zero-sum games)',
  'rl.chart.winSubtitle': 'Mapped from reward for RPS / Matching Pennies.',
  'rl.summary.title': 'Run Summary',
  'rl.summary.subtitle': 'Configuration + last policy snapshot.',
  'rl.summary.subtitleAggregated': 'Configuration + last policy snapshot (aggregated view).',
  'rl.axis.avgRewardA': 'avgRewardA',
  'rl.axis.winA': 'winA',
  'common.language': 'Language',
  'common.chartError': 'Chart failed to render.',
} as const;

type TranslationKey = keyof typeof en;
type Lang = 'en' | 'zh';

const zh: Record<TranslationKey, string> = {
  'lang.label': '语言',
  'lang.en': 'EN',
  'lang.zh': '中文',
  'nav.brand': '战略交互实验室',
  'nav.arena': '对战场',
  'nav.rl': '强化训练',
  'nav.notes': '笔记',
  'nav.eval': '评估',
  'nav.logout': '退出登录',
  'login.title': '登录',
  'login.subtitle': '登录 StrategicInteractionLab',
  'login.email': '邮箱',
  'login.password': '密码',
  'login.error': '登录失败',
  'login.useTest': '使用测试账号',
  'login.submit': '登录',
  'login.session': '可保存会话的对战模拟',
  'login.eval': '在线学习算法评估套件',
  'login.notes': '记录实验观察的个人笔记',
  'dashboard.artLabel': '多智能体动态',
  'dashboard.artAlt': '交互式数据可视化',
  'dashboard.greeting': '你好，{email}',
  'dashboard.live': '实验室在线',
  'dashboard.gameTheory': '博弈实验',
  'dashboard.metricEpisodes': '模拟轮次（演示）',
  'dashboard.metricEpisodesChip': '石头剪刀布 / 硬币 / 囚徒困境',
  'dashboard.metricStrategies': '策略数量',
  'dashboard.metricStrategiesChip': 'Hedge · Regret · FP',
  'dashboard.metricEval': '评估运行次数',
  'dashboard.metricEvalChip': '探索快照',
  'notes.title': '研究笔记',
  'notes.subtitle': '记录对战或评估实验中的即时观察。',
  'notes.pillTime': '时间戳笔记',
  'notes.pillUser': '按用户保存',
  'notes.placeholder': '写下一条笔记...',
  'notes.add': '添加',
  'notes.delete': '删除',
  'notes.empty': '还没有笔记。',
  'arena.title': '学习动力学对战场',
  'arena.subtitle': '运行重复博弈，观察在线学习在不同激励下的收敛情况。',
  'arena.pillRealtime': '实时模拟',
  'arena.pillSocket': 'Socket.IO 后端',
  'arena.pillHeatmap': '热力 + 轨迹视图',
  'arena.decisionTitle': '决策轨迹',
  'arena.decisionSubtitle': '查看每一步双方采取的具体动作。',
  'arena.downloadCsv': '下载步骤 CSV',
  'arena.latestSteps': '最新步骤',
  'arena.noSteps': '尚无记录。',
  'arena.avgRewardTitle': '平均收益（玩家1）',
  'arena.avgRewardSubtitle': '使用滑动窗口平滑的收益曲线。',
  'arena.strategyTitle': '策略分布（玩家1）',
  'arena.strategySubtitle': '跟踪 Hedge 更新下的混合策略演化。',
  'arena.heatTitle': '联合动作频率',
  'arena.heatSubtitle': '时间范围内的联合动作经验分布。',
  'arena.control.game': '博弈',
  'arena.control.rps': '石头剪刀布',
  'arena.control.mp': '对硬币',
  'arena.control.pd': '囚徒困境（2x2）',
  'arena.control.steps': '步数',
  'arena.control.seed': '随机种子',
  'arena.control.lr': '学习率（Hedge）',
  'arena.control.backend': '后端模式',
  'arena.control.backendLabel': '使用服务器（Socket.IO）',
  'arena.control.start': '开始',
  'arena.control.stop': '停止',
  'arena.control.reset': '重置',
  'arena.control.time': '步数 t = {t}',
  'arena.axis.t': 't',
  'arena.axis.reward': '收益',
  'arena.axis.p1': '玩家1',
  'arena.axis.p2': '玩家2',
  'arena.axis.player': '玩家',
  'arena.tooltip.freq': '{p1} 对 {p2}<br/>频率：{freq}%',
  'arena.tooltip.decision': 't = {t}<br/>{player} 选择了 {action}<br/>收益：{reward}',
  'arena.label.p1': '玩家1：',
  'arena.label.p2': '玩家2：',
  'arena.label.r1': 'r1：',
  'arena.label.r2': 'r2：',
  'eval.title': '算法评估套件',
  'eval.subtitle': '按多种种子与轮次批量实验，对比学习算法表现。',
  'eval.pillSummary': '汇总统计',
  'eval.pillDistribution': '分布视图',
  'eval.control.game': '博弈',
  'eval.control.algA': '算法 A',
  'eval.control.algB': '算法 B',
  'eval.alg.hedge': '乘法权重',
  'eval.alg.regret': '后悔匹配',
  'eval.alg.fp': '虚拟对策',
  'eval.control.seeds': '种子（逗号分隔）',
  'eval.control.episodes': '轮次',
  'eval.control.stepsPerEp': '每轮步数',
  'eval.control.lr': '学习率',
  'eval.control.run': '开始评估',
  'eval.summary.winA': 'A 胜率',
  'eval.summary.avgRewardA': 'A 平均收益',
  'eval.summary.coopRate': '合作率',
  'eval.summary.l2Dist': 'L2 距离',
  'eval.section.perStepTitle': '逐步决策',
  'eval.section.perStepSubtitle': '检查评估运行期间的每一步动作。',
  'eval.control.seed': '种子',
  'eval.control.episode': '轮次',
  'eval.downloadTrace': '下载步骤 CSV',
  'eval.noTrace': '运行评估后可查看步骤细节。',
  'eval.loadingTrace': '加载步骤中...',
  'eval.latestSteps': '最新步骤（所选种子/轮次）',
  'eval.noSteps': '暂无记录。',
  'eval.histTitle': 'A 胜率直方图',
  'eval.histSubtitle': '跨独立种子的 A 胜率分布。',
  'eval.rewardTitle': '各轮平均收益',
  'eval.rewardSubtitle': '按轮次聚合的 A 平均收益。',
  'eval.coopTitle': '合作率（A）',
  'eval.coopSubtitle': 'A 在囚徒困境中选择合作的比例。',
  'eval.l2Title': '距均匀分布的 L2',
  'eval.l2Subtitle': 'A 的策略距离均匀混合策略的程度。',
  'eval.tooltip.decision': '种子 {seed} · 轮次 {ep}<br/>t = {t}<br/>玩家 {player} 选择 {action}<br/>收益：{reward}',
  'eval.axis.t': 't',
  'eval.axis.player': '玩家',
  'eval.axis.avgRewardA': 'A 平均收益',
  'eval.axis.coopRate': '合作率',
  'eval.axis.l2Dist': 'L2 距离',
  'eval.axis.count': '计数',
  'eval.label.a': '玩家A：',
  'eval.label.b': '玩家B：',
  'eval.label.rA': 'rA：',
  'eval.label.rB': 'rB：',
  'rl.title': '深度强化学习训练（演示）',
  'rl.subtitle': '仅用 CPU 的自博弈策略梯度训练器，适用于小型矩阵博弈。',
  'rl.pillSelfPlay': '自博弈 PG',
  'rl.pillCpu': 'CPU 友好',
  'rl.pillDownload': '策略可下载',
  'rl.control.game': '博弈',
  'rl.control.pd': '囚徒困境',
  'rl.control.rps': '石头剪刀布',
  'rl.control.mp': '对硬币',
  'rl.control.episodes': '轮次',
  'rl.control.stepsPerEp': '每轮步数',
  'rl.control.lr': '学习率',
  'rl.control.hidden': '隐藏层规模',
  'rl.control.seed': '随机种子',
  'rl.control.distributed': '分布式演示',
  'rl.control.distributedLabel': '开启多工作进程聚合',
  'rl.control.workers': '工作进程数',
  'rl.control.train': '开始训练',
  'rl.control.download': '下载策略',
  'rl.chart.rewardTitle': '平均收益（A）',
  'rl.chart.rewardSubtitle': '跨轮次的收益轨迹。',
  'rl.chart.winTitle': '胜率（零和博弈）',
  'rl.chart.winSubtitle': '从 RPS / 对硬币的收益映射而来。',
  'rl.summary.title': '运行摘要',
  'rl.summary.subtitle': '配置与最新策略快照。',
  'rl.summary.subtitleAggregated': '配置与最新策略快照（聚合视图）。',
  'rl.axis.avgRewardA': 'A 平均收益',
  'rl.axis.winA': 'A 胜率',
  'common.language': '语言',
  'common.chartError': '图表渲染失败。',
};

const translations: Record<Lang, Record<TranslationKey, string>> = { en, zh };

type I18nContextValue = {
  lang: Lang;
  setLang: (lang: Lang) => void;
  t: (key: TranslationKey, vars?: Record<string, string | number>) => string;
};

const I18nContext = createContext<I18nContextValue | undefined>(undefined);

export const I18nProvider: React.FC<{ children: React.ReactNode }> = ({ children }) => {
  const [lang, setLangState] = useState<Lang>(() => {
    const stored = typeof localStorage !== 'undefined' ? (localStorage.getItem('lang') as Lang | null) : null;
    return stored === 'zh' ? 'zh' : 'en';
  });

  const setLang = useCallback((l: Lang) => {
    setLangState(l);
    if (typeof localStorage !== 'undefined') {
      localStorage.setItem('lang', l);
    }
  }, []);

  const t = useCallback((key: TranslationKey, vars?: Record<string, string | number>) => {
    const dict = translations[lang] || translations.en;
    const template = dict[key] ?? translations.en[key] ?? key;
    return template.replace(/\{(\w+)\}/g, (_, k) => (vars && k in vars ? String(vars[k]) : `{${k}}`));
  }, [lang]);

  const value = useMemo(() => ({ lang, setLang, t }), [lang, setLang, t]);

  return <I18nContext.Provider value={value}>{children}</I18nContext.Provider>;
};

export const useI18n = () => {
  const ctx = useContext(I18nContext);
  if (!ctx) throw new Error('useI18n must be used within I18nProvider');
  return ctx;
};

export type { Lang, TranslationKey };
